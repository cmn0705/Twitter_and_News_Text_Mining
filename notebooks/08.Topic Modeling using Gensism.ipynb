{
 "cells": [
  {
   "source": [
    "# Topic Modeling using Gensism\n",
    "\n",
    "Build topics model from the given messages in 'data/5.pulledTweet-deduplicated.csv'"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Unnamed: 0  Unnamed: 0.1  index                      created_at  \\\n",
       "219         219           227  251.0  Tue Apr 27 23:58:10 +0000 2021   \n",
       "220         220           228  252.0  Tue Apr 27 23:58:10 +0000 2021   \n",
       "221         221           229  253.0  Tue Apr 27 23:58:08 +0000 2021   \n",
       "222         222           230  254.0  Tue Apr 27 23:58:04 +0000 2021   \n",
       "223         223           231  255.0  Tue Apr 27 23:58:04 +0000 2021   \n",
       "\n",
       "               id                                               text language  \\\n",
       "219  1.387194e+18  Sometimes you get a third chance   Love s Thir...       en   \n",
       "220  1.387194e+18  Check out this Amazon deal  The Art of My Neig...       en   \n",
       "221  1.387194e+18    First Steps  How Upright Walking Made Us Hum...       en   \n",
       "222  1.387194e+18    The First Day of Spring by Nancy Tucker    B...       en   \n",
       "223  1.387194e+18  ad              off     Galaxy Star Projector ...       en   \n",
       "\n",
       "                                            shingleSet  \\\n",
       "219  {1975646848, 3508350977, 2277555713, 187718236...   \n",
       "220  {622155522, 3082850439, 1706091273, 1593029644...   \n",
       "221  {2352757504, 1318699267, 463207690, 4013102741...   \n",
       "222  {3712246153, 2391777162, 2684049684, 401310274...   \n",
       "223  {2473481, 4013102741, 566037670, 2455870758, 1...   \n",
       "\n",
       "                                             signature  \n",
       "219  [18622085, 32776440, 21561465, 191860621, 9160...  \n",
       "220  [116119196, 134412392, 15045377, 922378, 36390...  \n",
       "221  [77244016, 247586965, 343106086, 653196371, 20...  \n",
       "222  [8379671, 18718807, 281343041, 177753045, 3669...  \n",
       "223  [144950540, 122747773, 41607353, 97773221, 829...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Unnamed: 0.1</th>\n      <th>index</th>\n      <th>created_at</th>\n      <th>id</th>\n      <th>text</th>\n      <th>language</th>\n      <th>shingleSet</th>\n      <th>signature</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>219</th>\n      <td>219</td>\n      <td>227</td>\n      <td>251.0</td>\n      <td>Tue Apr 27 23:58:10 +0000 2021</td>\n      <td>1.387194e+18</td>\n      <td>Sometimes you get a third chance   Love s Thir...</td>\n      <td>en</td>\n      <td>{1975646848, 3508350977, 2277555713, 187718236...</td>\n      <td>[18622085, 32776440, 21561465, 191860621, 9160...</td>\n    </tr>\n    <tr>\n      <th>220</th>\n      <td>220</td>\n      <td>228</td>\n      <td>252.0</td>\n      <td>Tue Apr 27 23:58:10 +0000 2021</td>\n      <td>1.387194e+18</td>\n      <td>Check out this Amazon deal  The Art of My Neig...</td>\n      <td>en</td>\n      <td>{622155522, 3082850439, 1706091273, 1593029644...</td>\n      <td>[116119196, 134412392, 15045377, 922378, 36390...</td>\n    </tr>\n    <tr>\n      <th>221</th>\n      <td>221</td>\n      <td>229</td>\n      <td>253.0</td>\n      <td>Tue Apr 27 23:58:08 +0000 2021</td>\n      <td>1.387194e+18</td>\n      <td>First Steps  How Upright Walking Made Us Hum...</td>\n      <td>en</td>\n      <td>{2352757504, 1318699267, 463207690, 4013102741...</td>\n      <td>[77244016, 247586965, 343106086, 653196371, 20...</td>\n    </tr>\n    <tr>\n      <th>222</th>\n      <td>222</td>\n      <td>230</td>\n      <td>254.0</td>\n      <td>Tue Apr 27 23:58:04 +0000 2021</td>\n      <td>1.387194e+18</td>\n      <td>The First Day of Spring by Nancy Tucker    B...</td>\n      <td>en</td>\n      <td>{3712246153, 2391777162, 2684049684, 401310274...</td>\n      <td>[8379671, 18718807, 281343041, 177753045, 3669...</td>\n    </tr>\n    <tr>\n      <th>223</th>\n      <td>223</td>\n      <td>231</td>\n      <td>255.0</td>\n      <td>Tue Apr 27 23:58:04 +0000 2021</td>\n      <td>1.387194e+18</td>\n      <td>ad              off     Galaxy Star Projector ...</td>\n      <td>en</td>\n      <td>{2473481, 4013102741, 566037670, 2455870758, 1...</td>\n      <td>[144950540, 122747773, 41607353, 97773221, 829...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import pandas\n",
    "data4=pandas.read_csv('../data/5.pulledTweet-deduplicated.csv')\n",
    "data4.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Use CountVectorizor to find three letter tokens, remove stop_words, \n",
    "# remove tokens that don't appear in at least x documents,\n",
    "# remove tokens that appear in more than y% of the documents\n",
    "vect = CountVectorizer(min_df=1, max_df=0.4, stop_words='english')\n",
    "\n",
    "X = vect.fit_transform(data4['text'].astype(str))\n",
    "\n",
    "# Convert sparse matrix to gensim corpus.\n",
    "corpus = gensim.matutils.Sparse2Corpus(X, documents_columns=False)\n",
    "\n",
    "# Mapping from word IDs to words (To be used in LdaModel's id2word parameter)\n",
    "id_map = dict((v, k) for k, v in vect.vocabulary_.items())\n",
    "\n",
    "# Use the gensim.models.ldamodel.LdaModel constructor to estimate \n",
    "# LDA model parameters on the corpus, and save to the variable `ldamodel`\n",
    "\n",
    "ldamodel = gensim.models.ldamodel.LdaModel (corpus, id2word=id_map, passes=5)"
   ]
  },
  {
   "source": [
    "#### Print Most important topics, select number of topics and number of words in each topics you want"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(42,\n",
       "  '0.069*\"moonlak\" + 0.013*\"promo\" + 0.013*\"save\" + 0.013*\"code\" + 0.013*\"rfdk\"'),\n",
       " (48,\n",
       "  '0.030*\"switch\" + 0.030*\"st\" + 0.030*\"party\" + 0.030*\"sale\" + 0.030*\"gamestop\"'),\n",
       " (45,\n",
       "  '0.035*\"kiss\" + 0.035*\"alien\" + 0.035*\"ot\" + 0.035*\"read\" + 0.035*\"space\"'),\n",
       " (76,\n",
       "  '0.077*\"amzn\" + 0.069*\"growth\" + 0.069*\"change\" + 0.069*\"yoy\" + 0.069*\"facebook\"'),\n",
       " (11,\n",
       "  '0.094*\"items\" + 0.047*\"summer\" + 0.047*\"left\" + 0.047*\"lowest\" + 0.047*\"colored\"')]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "ldamodel.print_topics(num_topics=5, num_words=5)"
   ]
  },
  {
   "source": [
    "#### Topic distriution\n",
    "Given a document, this function returns a list of tuples, where each tuple is `(#topic, probability)`*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(34, 0.8899993)]"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "def topic_distribution(doc:str):\n",
    "    doc=[doc]\n",
    "    docVectorized = vect.transform(doc)\n",
    "    docCorpus = gensim.matutils.Sparse2Corpus(docVectorized, documents_columns=False)\n",
    "    result=[]\n",
    "    for item in ldamodel[docCorpus]:\n",
    "        result+=item\n",
    "    return result\n",
    "\n",
    "topic_distribution(\" We understand your concern  Some items may get shipped separately  To clarify  have we missed the delivery  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'0.061*\"ps\" + 0.061*\"usa\" + 0.059*\"best\" + 0.059*\"today\" + 0.030*\"game\" + 0.030*\"items\" + 0.030*\"amazon\"'"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "ldamodel.print_topic(topicno=34,topn=7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python370jvsc74a57bd0398dc28c06ad810e77de546bbdfa897a6ee0b83e59a5207339dda01a7843e01d",
   "display_name": "Python 3.7.0 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}